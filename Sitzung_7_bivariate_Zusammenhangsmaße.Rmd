
---
title: "Politikwissenschaftliche Statistik mit R. Sitzung 7: Bivariate Zusammenhangsmaße"
author:
- name: Christoph Garwe, Philipp Meyer, Laura Brune und Christoph Hönnige
  affiliation: Institut für Politikwissenschaft, Leibniz Universität Hannover
date: ''
output:
  html_document:
    toc: yes
    toc_depth: 2
    toc_float: yes
    theme: lumen
  pdf_document:
    toc: yes
    toc_depth: '2'
editor_options:
  chunk_output_type: console

---
<script>
  $(document).ready(function() {
    $head = $('#header');
    $head.prepend('<div class="knitr source"><img src="logo_IPW.png" width="160px" align="right"   ></div>')
  });
</script>

____
<br />

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# 1. Einleitung


In den vorherigen Sitzungen haben wir unsere Datensätze geladen, zur Analyse aufbereitet (umkodiert) und die Verteilungen einzelner Variablen mit (univariaten) Lage- und Streuungsmaßen sowie geeigneter Visualisierung inspiziert. Von nun an wollen wir *Zusammenhänge* zwischen den einzelnen Variablen der Datensätze prüfen. Wir betrachten also nicht nur eine, sondern (fürs erste) jeweils zwei Variablen. Damit befinden wir uns nun auf dem Gebiet der bivariaten Statistik. Wir prüfen, inwieweit bei einzelnen Beobachtungen ein Ausschlag auf einer Variable mit einem Ausschlag auf einer anderen Variable einhergeht. In dieser Sitzung werden wir herausfinden, wie wir bivariate Zusammenhangsmaße für nominales und metrisches Skalenniveau in `R` berechnen.

# 2. Datensätze laden und umkodieren

Damit wir mit unseren Datensätzen und den darin enthaltenen Variablen arbeiten können, müssen wir sie wie immer zuerst laden und zu unseren Zwecken umkodieren.
```{r eval=FALSE}
getwd()
setwd("eigener Pfad")
library(foreign)
gles <- read.spss(file = "ZA6801_de_v4-0-1.sav", to.data.frame = TRUE)
lijphart <- read.csv2("Lijphart_Data_recode.csv")
```
```{r include=FALSE}

library(foreign)
setwd("/Users/Christoph/Seafile/Lehrstuhl/Lehrstuhl Hannover Forschung/Forschung/01 Hönnige/025 MWK_StatistikR/Daten/")
getwd()
gles <- read.spss("ZA6801_de_v4-0-1.sav", to.data.frame = TRUE)
lijphart <- read.csv2("Lijphart_Data_recode.csv")
```
```{r}
# GLES
# Alter
q2c_num <- as.numeric(as.character(gles$q2c))
gles$alter <- 2017 - q2c_num

# Geschlecht
names(gles)[names(gles) == "q1"] <- "geschlecht"

# Einkommen kategorial
gles$einkommen_cat[gles$q192 == "unter 500 Euro" |
                     gles$q192 == "500 bis unter 750 Euro" |
                     gles$q192 == "750 bis unter 1000 Euro"] <- "weniger als 1000"
gles$einkommen_cat[gles$q192 == "1000 bis unter 1250 Euro" |
                     gles$q192 == "1250 bis unter 1500 Euro" |
                     gles$q192 == "1500 bis unter 2000 Euro"] <- "1000 bis 1999"
gles$einkommen_cat[gles$q192 == "2000 bis unter 2500 Euro" |
                     gles$q192 == "2500 bis unter 3000 Euro"] <- "2000 bis 2999"
gles$einkommen_cat[gles$q192 == "3000 bis unter 4000 Euro"] <- "3000 bis 3999"
gles$einkommen_cat[gles$q192 == "4000 bis unter 5000 Euro"] <- "4000 bis 4999"
gles$einkommen_cat[gles$q192 == "5000 bis unter 7500 Euro"] <- "5000 bis 7499"
gles$einkommen_cat[gles$q192 == "7500 bis unter 10000 Euro" |
                     gles$q192 == "10000 Euro und mehr"] <- "7500 und mehr"

gles$einkommen_cat <- factor(gles$einkommen_cat,
                                levels = c("weniger als 1000",
                                           "1000 bis 1999",
                                           "2000 bis 2999",
                                           "3000 bis 3999",
                                           "4000 bis 4999",
                                           "5000 bis 7499",
                                           "7500 und mehr"))

# Einkommen numerisch
gles$einkommen_num[gles$einkommen_cat == "weniger als 1000"] <- 1
gles$einkommen_num[gles$einkommen_cat == "1000 bis 1999"] <- 2
gles$einkommen_num[gles$einkommen_cat == "2000 bis 2999"] <- 3
gles$einkommen_num[gles$einkommen_cat == "3000 bis 3999"] <- 4
gles$einkommen_num[gles$einkommen_cat == "4000 bis 4999"] <- 5
gles$einkommen_num[gles$einkommen_cat == "5000 bis 7499"] <- 6
gles$einkommen_num[gles$einkommen_cat == "7500 und mehr"] <- 7

# Wohnort
gles$wohnort[gles$q197 == "Grossstadt"] <- "Großstadt"
gles$wohnort[gles$q197 == "kleine oder mittelgrosse Stadt"] <- "Kleinstadt"
gles$wohnort[gles$q197 == "laendliche Gegend oder Dorf"] <- "Land"
gles$wohnort[gles$q197 == "Vorstadt/ Vorort einer Grossstadt"] <- "Vorstadt"

# Links-Rechts-Selbsteinstufung
gles$LiRe <- as.character(gles$q32)
gles$LiRe[gles$LiRe == "1 links"] <- "1"
gles$LiRe[gles$LiRe == "11 rechts"] <- "11"
gles$LiRe <- as.numeric(gles$LiRe)

# Links-Rechts-Selbsteinstufung aggregiert
gles$LiRe_cat[gles$LiRe >= 1 &
                gles$LiRe <= 2] <- "links"
gles$LiRe_cat[gles$LiRe >= 3 &
                gles$LiRe <= 4] <- "moderat links"
gles$LiRe_cat[gles$LiRe >= 5 &
                gles$LiRe <= 7] <- "mittig"
gles$LiRe_cat[gles$LiRe >= 8 &
                gles$LiRe <= 9] <- "moderat rechts"
gles$LiRe_cat[gles$LiRe >= 10 &
                gles$LiRe <= 11] <- "rechts"

gles$LiRe_cat <- factor(gles$LiRe_cat,
                                levels = c("links",
                                           "moderat links",
                                           "mittig",
                                           "moderat rechts",
                                           "rechts"))

# AfD-Wahl
gles$AfD.Wahl[gles$q19ba == "AfD"] <- 1
gles$AfD.Wahl[gles$q19ba != "AfD"] <- 0

# Lijphart
# ENPP
lijphart$enpp4510 <- as.numeric(lijphart$enpp4510)

# Gallagher-Index
lijphart$disprop4510 <- as.numeric(lijphart$disprop4510)

# Bikameralismus-Index
lijphart$bicam4510 <- as.numeric(lijphart$bicam4510)

# Minimal-Gewinn-Koalition mit einer Partei
lijphart$minwin_one_part4510 <- as.numeric(lijphart$minwin_one_part4510)

# Exekutivdominanz (Kabinettsdauer)
lijphart$exe_dom4510 <- as.numeric(lijphart$exe_dom4510)
```

# 3. Nominales Skalenniveau

Für Zusammenhänge zwischen zwei nominalskalierten Variablen berechnen wir Chi-Quadrat und Cramer's V.

## 3.1 Chi-Quadrat

Wir beginnen mit Pearson's $\chi^2$-Unabhängigkeitstest, der die empirisch beobachtete Häufigkeit mit der bei Unterstellung von Unabhängigkeit zu erwartenden Häufigkeit vergleicht und prüft, ob diese signifikant unterschiedlich sind. Er wird auf Grundlage der Differenz zwischen der Indifferenztabelle und der Kontingenztabelle gebildet. Die Indifferenztabelle enthält in jeder Zelle die bei Unabhängigkeit erwarteten Häufigkeiten $e_{ij}$. Dagegen enthält die Kontingenztabelle in jeder Zelle die empirisch beobachteten Häufigkeiten $f_{ij}$ (Diaz-Bone 2019, 82):

$\chi^2=\sum_{j=1}^m\sum_{i=1}^k\frac{(f_{ij}-e_{ij})^2}{f_{ij}}$.

Eine Variable ist mit ihren Kategorien in den Zeilen und die andere Variable in den Spalten dieser Tabellen abgetragen. 

In `R` können wir Chi-Quadrat mit der Funktion `chisq.test()` berechnen. Wir beginnen mit dem angenommenen Zusammenhang zwischen der Wahl zugunsten oder zuungunsten der AfD und dem Wohnort der Befragten. Die Variablen `AfD.Wahl`und `wohnort` ordnen wir den Argumenten `x` und `y` zu. Keine der beiden Variablen weist eine natürliche Ordnung auf, sie sind also nominalskaliert. Wir speichern den Output von `chisq.test()` in dem Objekt `test_wohnort`. Wenn wir nun `test_wohnort` abschicken, zeigt `R` den Output der Funktion `chisq.test()`.

```{r}
test_wohnort <- chisq.test(gles$AfD.Wahl, gles$wohnort)
test_wohnort
```

$\chi^2$ ist deutlich größer als 1 und der p-Wert liegt nahe Null. Damit können wir mit großer Sicherheit die Annahme von Unabhängigkeit zwischen den beiden Variablen ablehnen. `R` hat den Wert im Hintergrund tatsächlich anhand der Tabellen empirisch beobachteter und bei Unabhängigkeit erwarteter Zellenhäufigkeiten errechnet. Das können wir nachvollziehen, indem wir uns beide Tabellen mit `test_wohnort$observed` (für die beobachteten) und `test_wohnort$expected` (für die erwarteten Häufigkeiten) ausgeben lassen. Sie sind als Teil des Outputs von `chisq.test()` in dem Objekt `test` gespeichert worden. Dabei steht die AfD-Wahl in den Zeilen und der Wohnort in den Spalten.

```{r}
test_wohnort$observed # beobachtete Häufigkeiten
test_wohnort$expected # bei Unabhängigkeit erwartete Häufigkeiten
```

Die Kreuztabelle der beobachteten Häufigkeiten lässt sich genauso händisch mit `table()` erstellen. Es ist häufig sinnvoll, bei unterstellten Zusammenhängen zwischen zwei Merkmalen für einen ersten Eindruck mittels `table()` Kreuztabellen zu erstellen.

```{r}
table(gles$AfD.Wahl, gles$wohnort)
```

Als weiteres Beispiel berechnen wir $\chi^2$ für den Zusammenhang zwischen der berichteten AfD-Wahl und dem Geschlecht der Befragten. Da beide Variablen dichotom sind (nur zwei Ausprägungen besitzen) und die dabei erstellten Tabellen somit das Format 2x2 aufweisen, wird eine Anpassung in der Berechnung vorgenommen ("Yates' continuity correction").

```{r}
test_geschlecht <- chisq.test(gles$AfD.Wahl, gles$geschlecht)
test_geschlecht
```

```{r}
test_geschlecht$observed # beobachtete Häufigkeiten
test_geschlecht$expected # bei Unabhängigkeit erwartete Häufigkeiten
```

In diesem Fall ist $\chi^2$ größer als zuvor und der p-Wert liegt näher an Null.

## 3.2 Cramer's V

Ein Nachteil von Chi-Quadrat ist, dass es je nach Tabellenformat und Fallzahl unterschiedlich ausfällt. Deshalb wird Cramer's V als Standardisierung von Chi-Quadrat auf den Wertebereich (0; 1) berechnet, indem man Chi-Quadrat mit Tabellenformat (geringere der Spalten- oder Zeilenanzahl -1) und Fallzahl verrechnet (Diaz-Bone 2019, 86):

$V=\sqrt{\frac{\chi^2}{n\cdot min(m-1;k-1)}}$.

So können wir die Stärke von Zusammenhängen vergleichen. Weil die drei oben untersuchten Variablen dem gleichen Datensatz entstammen, ist die Fallzahl identisch. Da außerdem die AfD-Wahl jeweils die Variable mit den wenigsten (nämlich zwei) Kategorien ist, dürfte die Normierung durch Cramer's V keinen Effekt haben. Der höhere $\chi^2$-Wert für den Zusammenhang von Geschlecht und AfD-Wahl im Vergleich zu dem Zusammenhang von Wohnort und AfD-Wahl, sollte auch für Cramer's V vorliegen.

Wir verwenden die Funktion `cramerV()` aus dem Paket `rcompanion`, da base-`R` keine Funktion zur Berechnung von Cramer's V bereithält. Entsprechend müssen wir `rcompanion` zunächst installieren und laden. Die Funktion `cramerV()` erwartet als Input eine Kreuztabelle der beobachteten Häufigkeiten. Wie oben gezeigt, können wir diese entweder händisch mittels `table(Variable1, Variable2)` erstellen, oder die durch `chisq.test()` erstellte Tabelle verwenden, die unter `test_wohnort$observed` gespeichert ist.

```{r eval=FALSE}
install.packages("rcompanion")
```
```{r}
library(rcompanion)
cramerV(table(gles$AfD.Wahl, gles$wohnort)) # aufgrund händisch erstellter Kreuztabelle
cramerV(test_wohnort$observed) # aufgrund von chisq.test() erstellter Kreuztabelle
```

Den Zusammenhang des Geschlechts mit der AfD-Wahl prüfen wir hier ausschließlich anhand des Outputs von `chisq.test()`.

```{r}
cramerV(test_geschlecht$observed) # aufgrund von chisq.test() erstellter Kreuztabelle
```

Wie wir erwartet haben, zeigt auch Cramer's V einen etwas stärkeren Zusammenhang zwischen dem Geschlecht und der AfD-Wahl, als zwischen dem Wohnort und der AfD Wahl. Tatsächlich müssen allerdings beide Zusammenhänge als schwach bezeichnet werden. 

# 4. Metrisches Skalenniveau

Den Zusammenhang zwischen zwei metrisch skalierten Variablen wollen wir mithilfe der Kovarianz und Pearson's Korrelationskoeffizient r ermitteln. Das Alter weist einen natürlichen Nullpunkt auf und ist somit ratioskaliert. Bei der Links-Rechts-Selbsteinstufung können wir zumindest gleichmäßige Intervalle zwischen zwei Skalenpunkten annehmen, weshalb sie mindestens als intervallskaliert gelten kann. Es handelt sich somit um metrische Merkmale.

# 4.1 Kovarianz

Zur Errechnung der Kovarianz wird für beide Variablen die Abweichung vom Mittelwert bestimmt und diese multipliziert. Schließlich wird das arithmetische Mittel über alle Beobachtungen hinweg gebildet (Diaz-Bone 2019, 92):

$cov(x;y)=\frac{1}{n}\sum_{i=1}^n(x_i-\overline{x})(y_i-\overline{y})$.

In `R` errechnen wir die Kovarianz mithilfe der Funktion `cov()`. Für das Alter und die Links-Rechts-Selbsteinstufung errechnen wir die Kovarianz wie folgt. Die Variablen `alter` und `LiRe` werden den Argumenten `x` und `y` zugewiesen. Da es sich dabei um die ersten beiden Argumente der Funktion handelt, sparen wir es uns, diese explizit zu nennen. Wir spezifizieren außerdem das Argument `use` mit `complete.obs`, wodurch wir festlegen, dass Beobachtungen (Zeilen), bei denen für eine der Variablen keine Information vorhanden ist (`NA`), bei der Berechnung nicht berücksichtigt werden.

```{r}
cov(gles$alter, gles$LiRe, use = "complete.obs")
```

Die Kovarianz für den Zusammenhang zwischen dem Alter der Befragten und der subjektiven Links-Rechts-Selbsteinstufung liegt bei etwa 3,77. Damit liegt ein positiver Zusammenhang vor. Da die Höhe des Wertes von den Ausprägungen der Variablen abhängt, kann die Stärke des Zusammenhangs nicht ohne Weiteres auf Grundlage der Kovarianz eingeschätzt werden.

# 4.2 Pearson's r

Allerdings können wir die Kovarianz auf den Wertebereich -1 bis 1 normieren, sodass wir ein Maß für die Stärke des Zusammenhangs erhalten. Das erreichen wir dadurch, dass wir sie durch das Produkt der Standardabweichungen beider Variablen dividieren (Diaz-Bone 2019, 94). So errechnen wir Pearson's Korrelationskoeffizienten

$r=\frac{cov(x;y)}{s_x\cdot s_y}=\frac{\frac{1}{n}\sum_{i=1}^n(x_i-\overline{x})(y_i-\overline{y})}{\sqrt{\frac{1}{n}\sum_{i=1}^n(x_i-\overline{x})^2}\sqrt{\frac{1}{n}\sum_{i=1}^n(y_i-\overline{y})^2}}$.

Die Funktionen zur Errechnung von Kovarianz und Korrelation in `R` sind identisch aufgebaut (siehe Hilfeseiten `?cor` oder `?cov`). Wir nennen wieder die Variablen `alter` und `LiRe` bei den Argumenten `x` und `y` (wieder implizit) und legen `use` so fest, dass Zeilen, in denen eine der Variablen ein `NA` aufweist, vor der Berechnung gelöscht werden.

```{r}
cor(gles$alter, gles$LiRe, use = "complete.obs")
```

Für den Zusammenhang von Alter und Links-Rechts-Selbsteinstufung errechnen wir für Pearson's r einen Wert von etwa 0,1. Damit liegt ein schwacher positiver Zusammenhang vor. Unter Berücksichtigung der Skalierung der Variablen können wir eine inhaltliche Interpretation ableiten. `LiRe` ist so gemessen, dass höhere Werte einer "rechteren" Selbsteinstufung entsprechen. Wir können also folgern, dass mit zunehmendem Alter der Befragten eine rechtere politische Position einhergeht.

# 5. Zusammenfassung

Bivariate Zusammenhangsmaße ermöglichen es uns zu prüfen, ob zwei Variablen voneinander unabhängig sind und wie stark ein zwischen ihnen bestehender Zusammenhang ist. Für metrische Merkmale ist es darüber hinaus möglich, die Richtung des Zusammenhangs (positiv oder negativ) zu bestimmen. In `R` lassen sich mit `table()` Kreuztabellen, mit `chisq.test()` Chi-Quadrat, mit `cramerV()` aus dem Paket `rcompanion` Cramer's V, mit `cov()` die Kovarianz und mit `cor()` der Korrelationskoeffizient r ermitteln.

# 6. Aufgaben

1. Bedeutet unsere Schlussfolgerung in 3.2, dass Menschen mit zunehmendem Alter eine eher rechte politische Einstellung entwickeln?
2. Finden Sie heraus, auf Grundlage welcher Variable wir die `AfD.Wahl` ursprünglich gebildet haben. Kodieren Sie diese Variable sinnvoll so um, dass sie die Wahlentscheiung der Befragten für die Parteien des Deutschen Bundestages enthält. Setzen Sie andere Antworten  auf `NA`. Erstellen Sie eine Kreuztabelle für die Wahlentscheidung und den Wohnort der Befragten.
3. Errechnen Sie Chi-Quadrat für die Wahlentscheidung und den Wohnort. Interpretieren Sie das Ergebnis. Lassen Sie sich die Tabellen der empirisch beobachteten und erwarteten Häufigkeiten ausgeben und vergleichen Sie sie. Berechnen Sie schließlich Cramer's V und interpretieren Sie das Ergebnis. 
4. Berechnen Sie die Kovarianz des Alters und des (zu einer numerischen Variable umgeformten) Haushaltseinkommens der Befragten. Berechnen Sie außerdem die Kovarianz des Gallagher-Indizes der Disproportionalität und der Effective Number of Parliamentary Parties (ENPP). Interpretieren Sie Ihre Ergebnisse.
5. Replizieren Sie einen Teil der Analyse Lijphart's aus "Patterns of Democracy": Berechnen Sie die Korrelation von (1) ENPP und Anteil von Minimal-Gewinnkoalitionen mit einer Partei, (2) Exekutivdominanz (Regierungsdauer) und Anteil von Minimal-Gewinnkoalitionen mit einer Partei, (3) Gallagher-Index und ENPP. Interpretieren Sie Ihre Ergebnisse. Wenn Sie eine Kopie von "Patterns of Democracy" vorliegen haben, vergleichen Sie Ihre Ergebnisse mit den Ergebnissen Lijpharts. Diese werden in den jeweils letzten Abschnitten der Kapitel 6, 7 und 8 diskutiert.